<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>IMPL</title><meta name="robots" content="index,follow"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@avneesh0612"/><meta name="twitter:creator" content="@avneesh0612"/><meta property="og:title" content="IMPL"/><meta property="og:url" content="https://www.avneesh.tech"/><meta property="og:image" content="/og-image.png"/><meta property="og:image:alt" content="IMPL"/><meta property="og:image:width" content="800"/><meta property="og:image:height" content="420"/><link rel="canonical" href="https://www.avneesh.tech"/><meta name="next-head-count" content="14"/><link href="/logo.svg" rel="icon"/><link href="/rss.xml" rel="alternate" title="RSS" type="application/rss+xml"/><meta content="/og-image.png" property="og:image"/><meta content="Avneesh, Agarwal, Avneesh Agarwal, web dev, blogger, content creator" name="keywords"/><link href="/manifest.json" rel="manifest"/><link href="/icon.png" rel="apple-touch-icon"/><meta content="#fff" name="theme-color"/><link rel="preload" href="/_next/static/css/a2554ebcfc03fd9a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a2554ebcfc03fd9a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-63157d71ad419e09.js" defer=""></script><script src="/_next/static/chunks/main-bdab2b2e4fcb4115.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da69e5539379a374.js" defer=""></script><script src="/_next/static/chunks/95b64a6e-090d2948d6dfa8fc.js" defer=""></script><script src="/_next/static/chunks/852-81b8b6b2a69076fe.js" defer=""></script><script src="/_next/static/chunks/35-dd5db76689e47c26.js" defer=""></script><script src="/_next/static/chunks/620-84bf34f9eb859ce3.js" defer=""></script><script src="/_next/static/chunks/pages/index-e9e97eb4a88239eb.js" defer=""></script><script src="/_next/static/KrYFfXck-offWzoZ9OmZ2/_buildManifest.js" defer=""></script><script src="/_next/static/KrYFfXck-offWzoZ9OmZ2/_ssgManifest.js" defer=""></script></head><body><div id="__next"><nav class="px-8 md:px-24 fixed md:py-4 py-6 bg-bgblue/60 backdrop-filter backdrop-blur-xl w-full max-w-[100vw] top-0 z-20  "><div class="flex justify-between items-center max-w-7xl mx-auto"><a href="intro" title="Avneesh"><svg class="cursor-pointer" fill="none" height="80" viewBox="0 0 86 50" width="220" xmlns="http://www.w3.org/2000/svg"><title>Avneesh Agarwal</title><path clip-rule="evenodd" d="M9.36 40 l-9.36 0 l0 -28.04 l9.36 0 l0 21.8 l-3.12 0 l0 -18.68 l-3.12 0 l0 21.8 l6.24 0 l0 3.12 z M31.672 27.84 l8.96 -15.88 l9.92 0 l0 28.04 l-9.36 0 l0 -10.48 l-5.96 10.48 l-7.16 0 l-9.08 -15.92 l0 -5.88 l10.92 18.68 l3.52 0 l10.88 -18.68 l0 18.68 l3.12 0 l0 -21.8 l-5 0 l-10.84 18.72 l-10.68 -18.72 l-5 0 l0 21.8 l3.08 0 l0 -5.88 l3.12 5.36 l0 3.64 l-9.32 0 l0 -28.04 l9.92 0 z M53.984 11.96 l22.84 0 c4.28 0 7.76 3.48 7.76 7.8 c0 4.28 -3.48 7.8 -7.76 7.8 l-19.72 -0.04 l0 9.36 l3.12 0 l0 -6.24 l3.08 0 l0 9.36 l-9.32 0 l0 -15.6 l22.84 0.04 c2.56 0 4.64 -2.12 4.64 -4.68 c0 -2.6 -2.08 -4.68 -4.64 -4.68 l-19.72 0 l0 3.12 l19.72 0 c0.8 0.04 1.48 0.72 1.48 1.56 s-0.64 1.52 -1.56 1.56 l-0.04 0 l-22.72 0 l0 -9.36 z M89.536 15.079999999999998 l0 15.56 l27.64 0 l0 9.36 l-30.76 0 l0 -3.12 l27.68 0 l0 -3.12 l-27.68 0 l0 -21.8 l9.36 0 l0 15.6 l-3.12 0 l0 -12.48 l-3.12 0 z" fill="white" fill-rule="evenodd"></path></svg></a><ol class="hidden space-x-8 md:flex"><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Home</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Publications</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Lab Members</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Join Us</a></p></ol></div></nav><div class="bg-white cursor-pointer md:hidden fixed grid h-14 place-items-center right-10 rounded-full top-4 w-14 z-50"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" color="black" style="color:black" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></div><div class="bg-bgblue px-10 flex-col gap-4 flex md:hidden justify-center items-center fixed min-h-[120vh] top-0 right-0 z-50
                    transition-all duration-500 ease-in-out 
                    translate-x-full"><div class="grid bg-white cursor-pointer h-12 absolute place-items-center rounded-full top-4 left-10 w-12"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" color="black" style="color:black" height="40" width="40" xmlns="http://www.w3.org/2000/svg"><path d="M278.6 256l68.2-68.2c6.2-6.2 6.2-16.4 0-22.6-6.2-6.2-16.4-6.2-22.6 0L256 233.4l-68.2-68.2c-6.2-6.2-16.4-6.2-22.6 0-3.1 3.1-4.7 7.2-4.7 11.3 0 4.1 1.6 8.2 4.7 11.3l68.2 68.2-68.2 68.2c-3.1 3.1-4.7 7.2-4.7 11.3 0 4.1 1.6 8.2 4.7 11.3 6.2 6.2 16.4 6.2 22.6 0l68.2-68.2 68.2 68.2c6.2 6.2 16.4 6.2 22.6 0 6.2-6.2 6.2-16.4 0-22.6L278.6 256z"></path></svg></div><div class="flex flex-col gap-4"><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Home</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Publications</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Lab Members</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Join Us</a></p></div></div><div class="flex flex-col items-center justify-center mt-40 space-y-10 md:justify-start md:items-start mb-10 w-full"><div style="z-index:-99"><div class="w-100 h-30 rounded-full bg-bgwhite fixed mx-auto my-auto blur-xl inset-0 opacity-5"></div></div><div class="space-y-5 max-w-7xl w-full mx-auto p-5 md:p-0" id="intro" style="transform:translateY(40px) translateZ(0)"><div class="w-3/5 md:w-3/5 text-textDark float-left"><div class="w-5/5 md:w-5/5 text-textDark "><p class="text-2xl text-neon font-fira">Welcome to </p><h1 class="text-5xl font-extrabold text-text md:text-5xl">Intelligent Machine Perception Lab</h1><h2 class="text-4xl text-textDark md:text-2xl">at Singapore University of Technology and Design</h2></div><div class="w-5/5 md:w-5/5 text-textDark "><span class="text-neon">We are a research group dedicated to pioneer novel and effective deep learning algorithms     for the practical advancement of intelligent machine perception.     Our research focus spans across two major areas:<!-- --> </span><p>(1) Computer Vision: 3D computer vision, (3D) scene understanding, 3D reconstruction. </p><p> (2) Machine Learning: data-efficient learning,     out-of-distribution learning, multi-modal learning, continual learning, robust learning.</p></div></div><img alt="data.username" loading="lazy" width="500" height="400" decoding="async" data-nimg="1" class="object-contain float-left w-3/9 " style="color:transparent" src="/sutd1.jpg"/></div><div class="space-y-5 max-w-7xl w-full mx-auto p-5 md:p-0 " id="work"><div class="flex items-center w-full mt-20" data-aos="fade-right" data-aos-delay="50" data-aos-duration="1000"><h2 class="text-3xl md:text-4xl text-text"><span class="text-neon font-fira"></span> <!-- -->News</h2><svg class="relative md:w-96 hidden md:inline-flex !ml-10" fill="none" height="2" viewBox="0 0 438 2" width="438" xmlns="http://www.w3.org/2000/svg"><path d="M0 1H438" stroke="#C7D3FF"></path></svg></div><div class="flex flex-col"><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->11 March 2024<!-- -->]</b>:   <!-- -->Congratulations to Hong Zexian for obtaining his master’s degree from NTU and continuing as a senior research assistant with us!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->1 March 2024<!-- -->]</b>:   <!-- -->We are delighted to welcome Wang Jiangyi and Qin You to join our lab as senior research assistants!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->27 Feb 2024<!-- -->]</b>:   <!-- -->One paper language-guided 3D affordance segmentation is accepted by CVPR 2024! Congratulations to Yicong!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->12 Feb 2024<!-- -->]</b>:   <!-- -->We are thrilled to welcome Prof. Liao Yiyi, our collaborator on the SUTD-ZJU project, for a two-week visit to our lab!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->29 Jan 2024<!-- -->]</b>:   <!-- -->One paper about semi-supervised 3D instance segmentation is accepted by ICRA 2024! Congratulations to Linfeng!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->17 Jan 2024<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for ECCV 2024.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->08 Jan 2024<!-- -->]</b>:   <!-- -->We are delighted to welcome Zhang Jie, a master student from XJUT, to visit our lab.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->23 Dec 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for ICML 2024.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->09 Dec 2023<!-- -->]</b>:   <!-- -->Two papers are accepted by AAAI 2024! Congratulations to all authors!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->08 Dec 2023<!-- -->]</b>:   <!-- -->Our lab receives a research grant from DSO! Thanks DSO! The grant will focus on cross-modality resiliency against real-world attacks.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->29 Oct 2023<!-- -->]</b>:   <!-- -->Prof. Na Zhao is invited as a reviewer for CVPR 2024.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->23 Oct 2023<!-- -->]</b>:   <!-- -->One paper about self-supervised point cloud representation learning is accepted by 3DV 2024 as an oral paper! Congratulations to Yunsong! </p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->14 Oct 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Zhuang Guohang, a PhD student from HFUT, to visit our lab.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->15 Sep 2023<!-- -->]</b>:   <!-- -->One paper about visual domain generalization is accepted by IJCV 2023! Congratulations to Yuyang! </p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->02 Sep 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Wang Chengshun and  Qian Peisheng  to join our lab as PhD students.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->01 Sep 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for ICLR 2024.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->19 Aug 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Jia Heng, a PhD student from ZJU, to visit our lab.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->25 Aug 2023<!-- -->]</b>:   <!-- -->One paper about robust few-shot point cloud segmentation is accepted by BMVC 2023! Congratulations to Yating!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->25 July 2023<!-- -->]</b>:   <!-- -->Our lab receives a research grant from A*STAR! Thanks A*STAR! The grant will focus on realistic deep learning for 3D vision.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->25 Jul 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to give a talk at DSO-TL@SUTD Dialogue Session.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->22 Jun 2023<!-- -->]</b>:   <!-- -->One paper about 6-DoF grasps synthesis is accepted by IROS 2023! Congratulations to Tasbolat!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->19 Jun 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to give a talk at the College of Computer Science, Zhejiang University.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->15 Jun 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to give a talk at the School of Computer Science, Fudan University.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->09 Jun 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to give a talk at the Intelligent Media Analysis Group, Nanjing University of Science and Technology.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->05 Jun 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Liu Chao to join our lab as a PhD student.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->04 Jul 2023<!-- -->]</b>:   <!-- -->One paper about generalized few-shot point cloud segmentation is accepted by ICCV 2023! Congratulations to Yating!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->26 May 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for IEEE’s Transactions on Knowledge and Data Engineering (TKDE).</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->26 May 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Pan Yining to join our lab as a PhD student. </p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->09 May 2023<!-- -->]</b>:   <!-- -->One paper about monocular 3D object detection is accepted by TCSVT 2023! Congratulations to Hualian!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->25 Apr 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Jiao Pengkun, a PhD student from FDU, to visit our lab.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->09 Apr 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for NeurIPS 2023.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->06 Mar 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as Demo Chair at Sixth IEEE International Conference on Multimedia Information Processing and Retrieval (MIPR) 2023!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->20 Feb 2023<!-- -->]</b>:   <!-- -->We are delighted to welcome Hong Zexian, a master student from NTU, to join our lab as an intern.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->06 Feb 2023<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for ICCV 2023.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->19 Dec 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a program committee for IJCAI 2023.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->15 Dec 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->09 Dec 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for IEEE Transactions on Image Processing (TIP).</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->15 Nov 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to join the Organising Committee of IEEE ICME 2023 Workshop on 3D Multimedia Analytics, Search and Generation!</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->02 Nov 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a reviewer for CVPR 2023.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->18 Oct 2022<!-- -->]</b>:   <!-- -->Our lab receives a research grant from SUTD-ZJU IDEA! Thanks SUTD-ZJU IDEA! This project will focus on multi-modal joint learning for scene understanding. </p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->28 Sep 2022<!-- -->]</b>:   <!-- -->Our lab receives a research grant from Temasek Laboratories @ SUTD! Thanks TL@SUTD! The project will focus on data-efficient 3D object detection for robot perception.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->03 Aug 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na is invited to serve as a program committee for AAAI 2023.</p></article><article class="flex flex-col items-center mt-4 md:flex-row text-neon text-1xl text-textDark"><p><b>[<!-- -->01 Aug 2022<!-- -->]</b>:   <!-- -->Prof. Zhao Na joins the Singapore University of Technology and Design as an Assistant Professor!</p></article></div></div><div class="z-50 flex flex-col items-center justify-center w-full" id="contact"><div class="flex items-center justify-center mt-10 space-x-5"><svg class="relative w-20 h-1 md:w-60" fill="none" height="2" viewBox="0 0 438 2" width="438" xmlns="http://www.w3.org/2000/svg"><path d="M0 1H438" stroke="#C7D3FF"></path></svg><h2 class="text-xl text-text md:text-4xl whitespace-nowrap">Get in Touch</h2><svg class="relative w-20 h-1 md:w-60" fill="none" height="2" viewBox="0 0 438 2" width="438" xmlns="http://www.w3.org/2000/svg"><path d="M0 1H438" stroke="#C7D3FF"></path></svg></div><div class="flex flex-wrap items-center justify-center mx-auto"><div><div><a class="items-center hidden px-5 py-2 mt-10 ml-0 duration-100 border-2 rounded-lg fill-current md:flex border-neon text-neon hover:scale-105" href="https://github.com/IMPL2023" rel="noreferrer" target="_blank"><img alt="GitHub" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" style="color:transparent" src="/logos/github.svg"/><span class="ml-2">GitHub</span></a><a class="flex items-center mt-10 duration-100 rounded-lg fill-current ml-0 md:hidden text-neon" href="https://github.com/IMPL2023" rel="noreferrer" target="_blank"><img alt="GitHub" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" style="color:transparent" src="/logos/github.svg"/></a></div></div><div><div><a class="items-center hidden px-5 py-2 mt-10 ml-6 md:ml-10 duration-100 border-2 rounded-lg fill-current md:flex border-neon text-neon hover:scale-105" href="mailto:na_zhao@sutd.edu.sg" rel="noreferrer" target="_blank"><img alt="Mail Us" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" style="color:transparent" src="/logos/mail.svg"/><span class="ml-2">Mail Us</span></a><a class="flex items-center mt-10 duration-100 rounded-lg fill-current ml-6 md:ml-10 md:hidden text-neon" href="mailto:na_zhao@sutd.edu.sg" rel="noreferrer" target="_blank"><img alt="Mail Us" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" style="color:transparent" src="/logos/mail.svg"/></a></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/","query":{},"buildId":"KrYFfXck-offWzoZ9OmZ2","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>