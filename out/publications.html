<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>IMPL</title><meta name="robots" content="index,follow"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@avneesh0612"/><meta name="twitter:creator" content="@avneesh0612"/><meta property="og:title" content="IMPL"/><meta property="og:url" content="https://www.avneesh.tech"/><meta property="og:image" content="/og-image.png"/><meta property="og:image:alt" content="IMPL"/><meta property="og:image:width" content="800"/><meta property="og:image:height" content="420"/><link rel="canonical" href="https://www.avneesh.tech"/><meta name="next-head-count" content="14"/><link href="/logo.svg" rel="icon"/><link href="/rss.xml" rel="alternate" title="RSS" type="application/rss+xml"/><meta content="/og-image.png" property="og:image"/><meta content="Avneesh, Agarwal, Avneesh Agarwal, web dev, blogger, content creator" name="keywords"/><link href="/manifest.json" rel="manifest"/><link href="/icon.png" rel="apple-touch-icon"/><meta content="#fff" name="theme-color"/><link rel="preload" href="/_next/static/css/a2554ebcfc03fd9a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a2554ebcfc03fd9a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-63157d71ad419e09.js" defer=""></script><script src="/_next/static/chunks/main-bdab2b2e4fcb4115.js" defer=""></script><script src="/_next/static/chunks/pages/_app-7c522eefc94d716d.js" defer=""></script><script src="/_next/static/chunks/95b64a6e-090d2948d6dfa8fc.js" defer=""></script><script src="/_next/static/chunks/852-81b8b6b2a69076fe.js" defer=""></script><script src="/_next/static/chunks/35-dd5db76689e47c26.js" defer=""></script><script src="/_next/static/chunks/620-3ed1d4a08afac054.js" defer=""></script><script src="/_next/static/chunks/pages/publications-fe2df4489ed1b722.js" defer=""></script><script src="/_next/static/IC6WnyeMGIW8h4K2ncxNI/_buildManifest.js" defer=""></script><script src="/_next/static/IC6WnyeMGIW8h4K2ncxNI/_ssgManifest.js" defer=""></script></head><body><div id="__next"><nav class="px-8 md:px-24 fixed md:py-4 py-6 bg-bgblue/60 backdrop-filter backdrop-blur-xl w-full max-w-[100vw] top-0 z-20  "><div class="flex justify-between items-center max-w-7xl mx-auto"><a href="intro" title="Avneesh"><svg class="cursor-pointer" fill="none" height="80" viewBox="0 0 86 50" width="220" xmlns="http://www.w3.org/2000/svg"><title>Avneesh Agarwal</title><path clip-rule="evenodd" d="M9.36 40 l-9.36 0 l0 -28.04 l9.36 0 l0 21.8 l-3.12 0 l0 -18.68 l-3.12 0 l0 21.8 l6.24 0 l0 3.12 z M31.672 27.84 l8.96 -15.88 l9.92 0 l0 28.04 l-9.36 0 l0 -10.48 l-5.96 10.48 l-7.16 0 l-9.08 -15.92 l0 -5.88 l10.92 18.68 l3.52 0 l10.88 -18.68 l0 18.68 l3.12 0 l0 -21.8 l-5 0 l-10.84 18.72 l-10.68 -18.72 l-5 0 l0 21.8 l3.08 0 l0 -5.88 l3.12 5.36 l0 3.64 l-9.32 0 l0 -28.04 l9.92 0 z M53.984 11.96 l22.84 0 c4.28 0 7.76 3.48 7.76 7.8 c0 4.28 -3.48 7.8 -7.76 7.8 l-19.72 -0.04 l0 9.36 l3.12 0 l0 -6.24 l3.08 0 l0 9.36 l-9.32 0 l0 -15.6 l22.84 0.04 c2.56 0 4.64 -2.12 4.64 -4.68 c0 -2.6 -2.08 -4.68 -4.64 -4.68 l-19.72 0 l0 3.12 l19.72 0 c0.8 0.04 1.48 0.72 1.48 1.56 s-0.64 1.52 -1.56 1.56 l-0.04 0 l-22.72 0 l0 -9.36 z M89.536 15.079999999999998 l0 15.56 l27.64 0 l0 9.36 l-30.76 0 l0 -3.12 l27.68 0 l0 -3.12 l-27.68 0 l0 -21.8 l9.36 0 l0 15.6 l-3.12 0 l0 -12.48 l-3.12 0 z" fill="white" fill-rule="evenodd"></path></svg></a><ol class="hidden space-x-8 md:flex"><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Home</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Publications</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Lab Members</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Join Us</a></p></ol></div></nav><div class="bg-white cursor-pointer md:hidden fixed grid h-14 place-items-center right-10 rounded-full top-4 w-14 z-50"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" color="black" style="color:black" height="30" width="30" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></div><div class="bg-bgblue px-10 flex-col gap-4 flex md:hidden justify-center items-center fixed min-h-[120vh] top-0 right-0 z-50
                    transition-all duration-500 ease-in-out 
                    translate-x-full"><div class="grid bg-white cursor-pointer h-12 absolute place-items-center rounded-full top-4 left-10 w-12"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" color="black" style="color:black" height="40" width="40" xmlns="http://www.w3.org/2000/svg"><path d="M278.6 256l68.2-68.2c6.2-6.2 6.2-16.4 0-22.6-6.2-6.2-16.4-6.2-22.6 0L256 233.4l-68.2-68.2c-6.2-6.2-16.4-6.2-22.6 0-3.1 3.1-4.7 7.2-4.7 11.3 0 4.1 1.6 8.2 4.7 11.3l68.2 68.2-68.2 68.2c-3.1 3.1-4.7 7.2-4.7 11.3 0 4.1 1.6 8.2 4.7 11.3 6.2 6.2 16.4 6.2 22.6 0l68.2-68.2 68.2 68.2c6.2 6.2 16.4 6.2 22.6 0 6.2-6.2 6.2-16.4 0-22.6L278.6 256z"></path></svg></div><div class="flex flex-col gap-4"><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Home</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Publications</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Lab Members</a></p><p class="border-b-2 border-transparent cursor-pointer text-text hover:border-neon"><a>Join Us</a></p></div></div><div class="flex flex-col items-center justify-center mt-40 space-y-10 md:justify-start md:items-start mb-10 w-full"><div style="z-index:-99"><div class="w-100 h-30 rounded-full bg-bgwhite fixed mx-auto my-auto blur-xl inset-0 opacity-5"></div></div><div class="max-w-7xl w-full mx-auto p-5 md:p-0" id="work"><div class="flex items-center w-full mt-20" data-aos="fade-right" data-aos-delay="50" data-aos-duration="1000"><h2 class="text-3xl md:text-4xl text-text"><span class="text-neon font-fira"></span> <!-- -->Publications:</h2><svg class="relative md:w-96 hidden md:inline-flex !ml-10" fill="none" height="2" viewBox="0 0 438 2" width="438" xmlns="http://www.w3.org/2000/svg"><path d="M0 1H438" stroke="#C7D3FF"></path></svg></div><div class="mt-4 text-textDark"></div><div class="flex flex-col"><article class="flex flex-col items-center mt-5 md:flex-row"><span class="text-2xl"><b>2024:</b></span></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Robust Visual Recognition.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Robust Visual Recognition with Class-Imbalanced Open-World Noisy Data</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">Thirty-Eighth AAAI Conference on Artificial Intelligence, 2024</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Dual-Perspective Knowledge.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Dual-Perspective Knowledge Enrichment for Semi-Supervised 3D Object Detection</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Yucheng Han</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao<sup>*</sup></b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Weiling Chen</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Keng-Teck Ma</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hanwang Zhang</span></span><span>* indicates corresponding author</span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">Thirty-Eighth AAAI Conference on Artificial Intelligence, 2024</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Enhancing Generalizability.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Enhancing Generalizability of Representation Learning for Data-Efficient 3D Scene Understanding</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Yunsong Wang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text">Oral Presentation</p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">International Conference on 3D Vision (3DV), 2024</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://na-z.github.io/">Code</a>]</span></span></div></article></div><div class="flex flex-col"><article class="flex flex-col items-center mt-5 md:flex-row"><span class="text-2xl"><b>2023:</b></span></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Style-Hallucinated.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Style-Hallucinated Dual Consistency Learning: A Unified Framework for Visual Domain Generalization</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Yuyang Zhao</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Zhun Zhong</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Nicu Sebe</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">International Journal on Computer Vision (IJCV), 2023</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://arxiv.org/pdf/2212.09068.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/HeliosZhao/SHADE-VisualDG">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Generalized-Few-Shot.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Generalized Few-Shot Point Cloud Segmentation Via Geometric Words</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Yating Xu</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Conghui Hu</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">International Conference on Computer Vision (ICCV), 2023</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://arxiv.org/pdf/2309.11222.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/Pixie8888/GFS-3DSeg_GWs">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/PDR.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">PDR: Progressive Depth Regularization for Monocular 3D Object Detection</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hualian Sheng</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Sijia Cai</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao<sup>#</sup></b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Bing Deng</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Min-Jian Zhao<sup>#</sup></span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><span># indicates co-corresponding author</span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://ieeexplore.ieee.org/abstract/document/10124735">PDF</a>]</span></span></div></article></div><div class="flex flex-col"><article class="flex flex-col  mt-5 "><div class=""><span class="text-2xl"><b>2022:</b></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Rethinking.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Rethinking IoU-based Optimization for Single-stage 3D Object Detection</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hualian Sheng</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Sijia Cai</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao<sup>*</sup></b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Bing Deng</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Jianqiang Huang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Xian-Sheng Hua</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Min-Jian Zhao</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><span>* indicates corresponding author</span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">European Conference on Computer Vision (ECCV), 2022</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://www.ecva.net//papers/eccv_2022/papers_ECCV//papers/136690536.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/hlsheng1/RDIoU">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Teaching.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Teaching with Soft Label Smoothing for Mitigating Noisy Labels in Facial Expressions</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tohar Lukov</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Ser-Nam Lim</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">European Conference on Computer Vision (ECCV), 2022</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://www.ecva.net//papers/eccv_2022/papers_ECCV//papers/136720639.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/toharl/soft">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Style-Hallucinated-Dual Consistency.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Style-Hallucinated Dual Consistency Learning for Domain Generalized Semantic Segmentation</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Yuyang Zhao</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Zhun Zhong</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Nicu Sebe</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">European Conference on Computer Vision (ECCV), 2022</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://www.ecva.net//papers/eccv_2022/papers_ECCV//papers/136880530.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/HeliosZhao/SHADE">Code</a>]</span></span></div></article><article class="flex flex-col items-center mt-10 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><img alt="" loading="lazy" width="450" height="250" decoding="async" data-nimg="1" class="relative md:w-[450px] pb-5 w-full ml-4 h-[250px] rounded-lg object-contain" style="color:transparent" src="/papers/Static-Dynamic.png"/><div class="ml-2 mt-5 md:mt-0 md:ml-20"><h3 class="text-2xl font-semibold text-neon">Static-Dynamic Co-Teaching for Class-Incremental 3D Object Detection</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-textDark mt-3 md:max-w-[700px] italic-text">Thirty-Sixth AAAI Conference on Artificial Intelligence, 2022 Oral Presentation</p><span class="text-textDark mt-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20254">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-neon" style="text-decoration:underline">[<a href="https://github.com/Na-Z/SDCoT">Code</a>]</span></span></div></article></div><div class="flex flex-col"><article class="flex flex-col  mt-5 mb-5"><div class=""><span class="text-2xl"><b>2021 and before:</b></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">Few-shot 3D Point Cloud Semantic Segmentation</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">IEEE Conference on Computer Vision and Patten Recognition (CVPR), 2021</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://arxiv.org/pdf/2006.12052.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://www.youtube.com/watch?v=i5X1L1_03Rs">Video</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://github.com/Na-Z/attMPTI">Code</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">SESS: Self-Ensembling Semi-Supervised 3D Object Detection</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">IEEE Conference on Computer Vision and Patten Recognition (CVPR), 2020 Oral Presentation</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://arxiv.org/pdf/1912.11803.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://www.youtube.com/watch?v=AGJsp4aksS0">Video</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://github.com/Na-Z/sess">Code</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">PS^2-Net: A Locally and Globally Aware Network for Point-Based Semantic Segmentation</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Gim Hee Lee</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">25th International Conference on Pattern Recognition (ICPR), 2020</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://arxiv.org/pdf/1908.05425.pdf">PDF</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://www.youtube.com/watch?v=IupewGCU0o8">Video</a>]</span></span><span class="text-textDark mt-2 ml-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://github.com/Na-Z/PS-2Net">Code</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">End2End semantic segmentation for 3D indoor scenes</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">Proceedings of the 26th ACM international conference on Multimedia, 2018</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://dl.acm.org/doi/pdf/10.1145/3240508.3243933">PDF</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">VIDEOWHISPER: Towards unsupervised learning of discriminative features of videos with RNN</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hanwang Zhang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Richang Hong</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Meng Wang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">IEEE International Conference on Multimedia and Expo (ICME), 2017</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://ieeexplore.ieee.org/iel7/8014303/8019290/08019344.pdf">PDF</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">Learning content–social influential features for influence analysis</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hanwang Zhang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Meng Wang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Richang Hong</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">International Journal of Multimedia Information Retrieval, 2016</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://sutd.primo.exlibrisgroup.com/openurl/65SUTD_INST/65SUTD_INST:65SUTD?sid=google&amp;auinit=N&amp;aulast=Zhao&amp;atitle=Learning+content%E2%80%93social+influential+features+for+influence+analysis&amp;id=doi:10.1007/s13735-016-0102-y&amp;title=IJMIR&amp;volume=5&amp;date=2016&amp;spage=137&amp;issn=2192-6611">PDF</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">Discrete image hashing using large weakly annotated photo collections</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Hanwang Zhang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Xindi Shang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Huanbo Luan</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-seng Chua</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">Proceedings of the AAAI Conference on Artificial Intelligence, 2016</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://ojs.aaai.org/index.php/AAAI/article/download/10453/10312">PDF</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">Searching for recent celebrity images in microblog platform</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Richang Hong</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Meng Wang</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Xuegang Hu</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Tat-Seng Chua</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">Proceedings of the 22nd ACM international conference on Multimedia, 2014</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://dl.acm.org/doi/pdf/10.1145/2647868.2655011">PDF</a>]</span></span></div></article><article class="flex flex-col items-center mb-5 md:flex-row" style="border-bottom:2px solid rgba(255, 255, 255, 0.1)"><div class="ml-2 mt-10 mb-2 md:mt-0 md:ml-5"><h3 class="text-base font-semibold text-neon">Automatic image annotation by semi-supervised manifold kernel density estimation</h3><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Ping Ji</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><b>Na Zhao</b></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Shijie Hao</span></span><span class="inline-block bg-text text-darkerBlue rounded-full px-3 py-1 mt-2 mr-2"><span>Jianguo Jiang</span></span><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text"></p><p class="text-base text-textDark mt-3 md:max-w-[700px] italic-text">Information Sciences, 2014</p><span class="text-textDark mt-2"><span class="text-base text-neon" style="text-decoration:underline">[<a href="https://www.sciencedirect.com/science/article/pii/S0020025513006580">PDF</a>]</span></span></div></article></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/publications","query":{},"buildId":"IC6WnyeMGIW8h4K2ncxNI","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>